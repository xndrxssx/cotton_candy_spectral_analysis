{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Definindo o caminho base para a pasta Pre-processamento\n",
    "base_path = Path(parent_dir) / 'Partial Components Analysis'\n",
    "\n",
    "file_path_raw_cal = base_path / 'RAW_calibration.xlsx'\n",
    "file_path_msc_cal = base_path / 'MSC_calibration.xlsx'\n",
    "file_path_snv_cal = base_path / 'SNV_calibration.xlsx'\n",
    "file_path_sg_cal = base_path / 'SG_calibration.xlsx'\n",
    "\n",
    "df_raw_cal = pd.read_excel(file_path_raw_cal)\n",
    "df_msc_cal = pd.read_excel(file_path_msc_cal)\n",
    "df_snv_cal = pd.read_excel(file_path_snv_cal)\n",
    "df_sg_cal = pd.read_excel(file_path_sg_cal)\n",
    "\n",
    "file_path_raw_val = base_path / 'RAW_validation.xlsx'\n",
    "file_path_msc_val = base_path / 'MSC_validation.xlsx'\n",
    "file_path_snv_val = base_path / 'SNV_validation.xlsx'\n",
    "file_path_sg_val = base_path / 'SG_validation.xlsx'\n",
    "\n",
    "df_raw_val = pd.read_excel(file_path_raw_val)\n",
    "df_msc_val = pd.read_excel(file_path_msc_val)\n",
    "df_snv_val = pd.read_excel(file_path_snv_val)\n",
    "df_sg_val = pd.read_excel(file_path_sg_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = df_msc_val.iloc[:,6:], df_msc_val['SST'].values\n",
    "X_train, y_train = df_msc_cal.iloc[:,6:], df_msc_cal['SST'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((175, 2151), (75, 2151))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=[cols])\n",
    "\n",
    "X_test = pd.DataFrame(X_test, columns=[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Metrics ===\n",
      "Correlation coefficient: 0.8412\n",
      "Mean absolute error: 1.1296\n",
      "Root mean squared error: 1.4467\n",
      "Relative absolute error: 51.1622\n",
      "Root relative squared error: 54.4611\n",
      "Total Number of Instances: 175.0000\n",
      "\n",
      "=== Cross-Validation Metrics ===\n",
      "Correlation coefficient: 0.8206\n",
      "Mean absolute error: 1.2188\n",
      "Root mean squared error: 1.5218\n",
      "Relative absolute error: 55.1982\n",
      "Root relative squared error: 57.2899\n",
      "Total Number of Instances: 175.0000\n",
      "\n",
      "=== Validation Metrics ===\n",
      "Correlation coefficient: 0.7561\n",
      "Mean absolute error: 1.1345\n",
      "Root mean squared error: 1.3879\n",
      "Relative absolute error: 65.8249\n",
      "Root relative squared error: 65.9550\n",
      "Total Number of Instances: 75.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Função para calcular as métricas\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    correlation_coefficient = np.corrcoef(y_true, y_pred)[0, 1]\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mean_y_true = np.mean(y_true)\n",
    "    relative_absolute_error = 100 * (mae / np.mean(np.abs(y_true - mean_y_true)))\n",
    "    root_relative_squared_error = 100 * (rmse / np.std(y_true))\n",
    "\n",
    "    return {\n",
    "        \"Correlation coefficient\": correlation_coefficient,\n",
    "        \"Mean absolute error\": mae,\n",
    "        \"Root mean squared error\": rmse,\n",
    "        \"Relative absolute error\": relative_absolute_error,\n",
    "        \"Root relative squared error\": root_relative_squared_error,\n",
    "        \"Total Number of Instances\": len(y_true)\n",
    "    }\n",
    "    \n",
    "def display_metrics(title, metrics):\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "model = SVR(\n",
    "    C=1.0,             # Regularização\n",
    "    epsilon=0.001,     # Tolerância\n",
    "    kernel='poly',     # Kernel polinomial\n",
    "    degree=1,          # Grau do polinômio\n",
    "    coef0=1,           # Coeficiente do polinômio\n",
    "    tol=1.0E-12        # Tolerância de precisão\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de treinamento\n",
    "y_train_pred = model.predict(X_train)\n",
    "training_metrics = calculate_metrics(y_train, y_train_pred)\n",
    "display_metrics(\"Training Metrics\", training_metrics)\n",
    "\n",
    "folds = 175  # Defina o número de folds para a validação cruzada\n",
    "y_train_cv = cross_val_predict(model, X_train, y_train, cv=folds)\n",
    "cv_metrics = calculate_metrics(y_train, y_train_cv)\n",
    "display_metrics(\"Cross-Validation Metrics\", cv_metrics)\n",
    "\n",
    "y_pred_val = model.predict(X_test)\n",
    "validation_metrics = calculate_metrics(y_test, y_pred_val)\n",
    "display_metrics(\"Validation Metrics\", validation_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
