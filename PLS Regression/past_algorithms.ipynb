{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from sys import stdout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmo PLSR\n",
    "def pretreat(X, method):\n",
    "    if method == 'autoscaling':\n",
    "        scaler = StandardScaler()\n",
    "        Xs = scaler.fit_transform(X)\n",
    "        return Xs, scaler.mean_, scaler.scale_\n",
    "    elif method == 'center':\n",
    "        mean = np.mean(X, axis=0)\n",
    "        Xs = X - mean\n",
    "        return Xs, mean\n",
    "    else:\n",
    "        return X, 0, 1\n",
    "def optimise_pls_cv(X, y, n_comp, max_iter=100, method='center'):\n",
    " \n",
    "    '''Run PLS including a variable number of components, up to n_comp,\n",
    "       and calculate MSE '''\n",
    " \n",
    "    mse = []\n",
    "    component = np.arange(1, n_comp+1)\n",
    "    \n",
    "    X, mean_X = pretreat(X, method)  # Centralizando os dados\n",
    "    y, mean_y = pretreat(y, method)\n",
    " \n",
    "    for i in component:\n",
    "        pls = PLSRegression(n_components=i)\n",
    " \n",
    "        # Cross-validation\n",
    "        y_cv = cross_val_predict(pls, X, y, cv=10)\n",
    " \n",
    "        mse.append(mean_squared_error(y, y_cv))\n",
    " \n",
    "        comp = 100*(i+1)/n_comp\n",
    "        # Trick to update status on the same line\n",
    "        stdout.write(\"\\r%d%% completed\" % comp)\n",
    "        stdout.flush()\n",
    "    stdout.write(\"\\n\")\n",
    " \n",
    "    # Calculate and print the position of minimum in MSE\n",
    "    msemin = np.argmin(mse)\n",
    "    print(\"Suggested number of components: \", msemin+1)\n",
    "    stdout.write(\"\\n\")\n",
    "    \n",
    " \n",
    "    # Define PLS object with optimal number of components\n",
    "    pls_opt = PLSRegression(n_components=msemin+1)\n",
    " \n",
    "    # Fir to the entire dataset\n",
    "    pls_opt.fit(X, y)\n",
    "    y_c = pls_opt.predict(X)\n",
    " \n",
    "    # Cross-validation\n",
    "    y_cv = cross_val_predict(pls_opt, X, y, cv=10)\n",
    " \n",
    "    # Calculate scores for calibration and cross-validation\n",
    "    score_c = r2_score(y, y_c)\n",
    "    score_cv = r2_score(y, y_cv)\n",
    " \n",
    "    # Calculate mean squared error for calibration and cross validation\n",
    "    mse_c = mean_squared_error(y, y_c)\n",
    "    mse_cv = mean_squared_error(y, y_cv)\n",
    "    \n",
    "    rmse_c = np.sqrt(mean_squared_error(y, y_c))\n",
    "    rmse_cv = np.sqrt(mean_squared_error(y, y_cv))\n",
    "    \n",
    "    rpd_value = y.std() / np.sqrt(rmse_cv)\n",
    " \n",
    "    print('R2 calib: %5.3f'  % score_c)\n",
    "    print('R2 CV: %5.3f'  % score_cv)\n",
    "    print('RMSE calib: %5.3f' % rmse_c)\n",
    "    print('RMSE CV: %5.3f' % rmse_cv)\n",
    "    print('RPD: %5.3f' % rpd_value)\n",
    " \n",
    "\n",
    "    # Fit a line to the CV vs response\n",
    "    z = np.polyfit(y, y_c, 1)\n",
    "    with plt.style.context(('ggplot')):\n",
    "        fig, ax = plt.subplots(figsize=(9, 5))\n",
    "        ax.scatter(y_c, y, c='red', edgecolors='k')\n",
    "        #Plot the best fit line\n",
    "        ax.plot(np.polyval(z,y), y, c='blue', linewidth=1)\n",
    "        #Plot the ideal 1:1 line\n",
    "        ax.plot(y, y, color='green', linewidth=1)\n",
    "        plt.title('$R^{2}$ (CV): '+str(score_cv))\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Measured')\n",
    " \n",
    "        plt.show()\n",
    " \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que você já tenha suas matrizes X e Y\n",
    "# Calculando as médias\n",
    "X_mean = X.mean(axis=0)\n",
    "Y_mean = Y['SST'].mean(axis=0)\n",
    "\n",
    "# Centralizando as matrizes\n",
    "Xc = X - np.ones((X.shape[0], 1)) * X_mean\n",
    "Yc = Y - np.ones((Y.shape[0], 1)) * Y_mean\n",
    "\n",
    "H = 10  # número de iterações\n",
    "w = np.zeros((Xc.shape[1], H))\n",
    "t = np.zeros((Xc.shape[0], H))\n",
    "p = np.zeros((Xc.shape[1], H))\n",
    "q = np.zeros((H, 1))\n",
    "\n",
    "# Iteração sobre H\n",
    "for h in range(H):\n",
    "    v = np.dot(Xc.T, Yc)\n",
    "    w[:, h] = v / np.sqrt(np.dot(v.T, v))\n",
    "    norm_w_h = np.linalg.norm(w[:, h])\n",
    "    print(\"norma=\" + norm_w_h)\n",
    "    t[:, h] = np.dot(Xc, w[:, h])\n",
    "    tt = np.dot(t[:, h].T, t[:, h])\n",
    "    p[:, h] = np.dot(Xc.T, t[:, h]) / tt\n",
    "    R = Xc - np.outer(t[:, h], p[:, h].T)\n",
    "    q[h] = np.dot(t[:, h].T, Yc) / tt\n",
    "\n",
    "# Calculando b\n",
    "b = np.cumsum(np.dot(w, np.dot(np.linalg.inv(np.dot(p.T, w)), np.diag(q.flatten()))), axis=1)\n",
    "\n",
    "# Se necessário, você pode converter os resultados finais para DataFrame do pandas\n",
    "b_df = pd.DataFrame(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1th group finished.\n",
      "The 2th group finished.\n",
      "The 3th group finished.\n",
      "The 4th group finished.\n",
      "The 5th group finished.\n",
      "The 6th group finished.\n",
      "The 7th group finished.\n",
      "The 8th group finished.\n",
      "The 9th group finished.\n",
      "The 10th group finished.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[31], line 141\u001b[0m\n",
      "\u001b[0;32m    139\u001b[0m X_array \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[0;32m    140\u001b[0m Y_array \u001b[38;5;241m=\u001b[39m Y[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSST\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[1;32m--> 141\u001b[0m \u001b[43mplscv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcenter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\n",
      "Cell \u001b[1;32mIn[31], line 114\u001b[0m, in \u001b[0;36mplscv\u001b[1;34m(X, y, A, K, method, PROCESS, order)\u001b[0m\n",
      "\u001b[0;32m    110\u001b[0m Q2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (np\u001b[38;5;241m.\u001b[39msum((YR[:, i] \u001b[38;5;241m-\u001b[39m y)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m SST) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(A)]\n",
      "\u001b[0;32m    112\u001b[0m indexSD \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(error2_MEAN \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(error2_MEAN) \u001b[38;5;241m+\u001b[39m error2_SD[index])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;32m--> 114\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n",
      "\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMethod\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYpred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mYR\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPredError\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRMSECV\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQ2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ2\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRMSECV_min\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mRMSEP\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQ2_max\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOptLV\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNote\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m*** The following is based on global min MSE + 1SD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRMSECV_min_1SD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindexSD\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQ2_max_1SD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindexSD\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOptLV_1SD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexSD\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "\u001b[0;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results_df\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Luyza\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:767\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n",
      "\u001b[0;32m    761\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n",
      "\u001b[0;32m    762\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n",
      "\u001b[0;32m    763\u001b[0m     )\n",
      "\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[0;32m    766\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n",
      "\u001b[1;32m--> 767\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n",
      "\u001b[0;32m    769\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Luyza\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n",
      "\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n",
      "\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n",
      "\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Luyza\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n",
      "\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n",
      "\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n",
      "\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Luyza\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n",
      "\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n",
      "\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n",
      "\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    682\u001b[0m     )\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "\n",
    "def pretreat(X, method):\n",
    "    if method == 'autoscaling':\n",
    "        scaler = StandardScaler()\n",
    "        Xs = scaler.fit_transform(X)\n",
    "        return Xs, scaler.mean_, scaler.scale_\n",
    "    elif method == 'center':\n",
    "        mean = np.mean(X, axis=0)\n",
    "        Xs = X - mean\n",
    "        return Xs, mean, 1\n",
    "    else:\n",
    "        return X, 0, 1\n",
    "\n",
    "def plsnipals(X, Y, A):\n",
    "    varX = np.sum(np.sum(X**2))\n",
    "    varY = np.sum(np.sum(Y**2))\n",
    "    \n",
    "    n, p = X.shape\n",
    "    _, m = Y.shape\n",
    "    \n",
    "    W = np.zeros((p, A))\n",
    "    T = np.zeros((n, A))\n",
    "    P = np.zeros((p, A))\n",
    "    Q = np.zeros((m, A))\n",
    "    \n",
    "    for i in range(A):\n",
    "        error = 1\n",
    "        u = Y[:, 0]\n",
    "        niter = 0\n",
    "        while error > 1e-8 and niter < 1000:\n",
    "            w = X.T @ u / (u.T @ u)\n",
    "            w = w / np.linalg.norm(w)\n",
    "            t = X @ w\n",
    "            q = Y.T @ t / (t.T @ t)\n",
    "            u1 = Y @ q / (q.T @ q)\n",
    "            error = np.linalg.norm(u1 - u) / np.linalg.norm(u)\n",
    "            u = u1\n",
    "            niter += 1\n",
    "        \n",
    "        p = X.T @ t / (t.T @ t)\n",
    "        X = X - np.outer(t, p.T)\n",
    "        Y = Y - np.outer(t, q.T)\n",
    "        \n",
    "        W[:, i] = w\n",
    "        T[:, i] = t\n",
    "        P[:, i] = p\n",
    "        Q[:, i] = q\n",
    "    \n",
    "    R2X = np.diag(T.T @ T @ P.T @ P) / varX\n",
    "    R2Y = np.diag(T.T @ T @ Q.T @ Q) / varY\n",
    "    \n",
    "    Wstar = W @ np.linalg.inv(P.T @ W)\n",
    "    B = Wstar @ Q.T\n",
    "    \n",
    "    return B, Wstar, T, P, Q, W, R2X, R2Y\n",
    "\n",
    "def plscv(X, y, A=3, K=10, method='center', PROCESS=1, order=0):\n",
    "    if order == 0:\n",
    "        indexyy = np.argsort(y)\n",
    "    elif order == 1:\n",
    "        indexyy = np.random.permutation(len(y))\n",
    "    elif order == 2:\n",
    "        indexyy = np.arange(len(y))\n",
    "    \n",
    "    X = X[indexyy, :]\n",
    "    y = y[indexyy]\n",
    "    \n",
    "    Mx, Nx = X.shape\n",
    "    A = min([X.shape[1], A])\n",
    "    yytest = np.full(Mx, np.nan)\n",
    "    YR = np.full((Mx, A), np.nan)\n",
    "    \n",
    "    kf = KFold(n_splits=K)\n",
    "    \n",
    "    for group, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        Xcal, Xtest = X[train_index], X[test_index]\n",
    "        ycal, ytest = y[train_index], y[test_index]\n",
    "        \n",
    "        Xs, xpara1, xpara2 = pretreat(Xcal, method)\n",
    "        ys, ypara1, ypara2 = pretreat(ycal, 'center')\n",
    "        \n",
    "        B, Wstar, T, P, Q, W, R2X, R2Y = plsnipals(Xs, ys[:, np.newaxis], A)\n",
    "        \n",
    "        yp = np.zeros((Xtest.shape[0], A))\n",
    "        for j in range(A):\n",
    "            Bj = Wstar[:, :j+1] @ Q[:j+1]\n",
    "            C = ypara2 * Bj / xpara2\n",
    "            coef = np.vstack([C, ypara1 - np.sum(xpara1 * C)])\n",
    "            Xteste = np.hstack([Xtest, np.ones((Xtest.shape[0], 1))])\n",
    "            ypred = Xteste @ coef\n",
    "            yp[:, j] = ypred.flatten()\n",
    "        \n",
    "        YR[test_index, :] = yp\n",
    "        yytest[test_index] = ytest\n",
    "        if PROCESS == 1:\n",
    "            print(f'The {group+1}th group finished.')\n",
    "    \n",
    "    YR[indexyy, :] = YR\n",
    "    y = y[indexyy]\n",
    "    \n",
    "    error = YR - y[:, np.newaxis]\n",
    "    error2 = error**2\n",
    "    error2_MEAN = np.mean(error2, axis=0)\n",
    "    error2_SD = np.std(error2, axis=0, ddof=1)\n",
    "    \n",
    "    cv = np.sqrt(error2_MEAN)\n",
    "    RMSEP = np.min(cv)\n",
    "    index = np.argmin(cv)\n",
    "    SST = np.sum((yytest - np.mean(y))**2)\n",
    "    \n",
    "    Q2 = [1 - (np.sum((YR[:, i] - y)**2) / SST) for i in range(A)]\n",
    "    \n",
    "    indexSD = np.where(error2_MEAN <= np.min(error2_MEAN) + error2_SD[index])[0][0]\n",
    "    \n",
    "    results_df = pd.DataFrame({\n",
    "        'Method': method,\n",
    "        'Ypred': [list(row) for row in YR],\n",
    "        'PredError': [list(row) for row in error],\n",
    "        'RMSECV': cv,\n",
    "        'Q2': Q2,\n",
    "        'RMSECV_min': RMSEP,\n",
    "        'Q2_max': Q2[index],\n",
    "        'OptLV': index + 1,\n",
    "        'Note': '*** The following is based on global min MSE + 1SD',\n",
    "        'RMSECV_min_1SD': cv[indexSD],\n",
    "        'Q2_max_1SD': Q2[indexSD],\n",
    "        'OptLV_1SD': indexSD + 1\n",
    "    })\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# Exemplo de uso:\n",
    "# X = ... # Sua matriz de entrada (m x n)\n",
    "# y = ... # Seu vetor de resposta (m x 1)\n",
    "# A = ... # Número máximo de variáveis latentes\n",
    "# K = ... # Número de folds para validação cruzada\n",
    "# method = ... # Método de pré-processamento ('autoscaling', 'pareto', 'minmax', 'center', 'none')\n",
    "# PROCESS = ... # Imprimir progresso (1 para sim, 0 para não)\n",
    "# order = ... # Ordem dos dados (0 para ordenado, 1 para aleatório, 2 para original)\n",
    "X_array = X.values\n",
    "Y_array = Y['SST'].values\n",
    "plscv(X_array, Y_array, 1, 10, 'center', 1, 2)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
